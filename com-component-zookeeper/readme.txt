zk集群部署
    1、centOs环境安装zk
    2、配置 myid、conf
    3、zkServer.sh start 启动  zkServer.sh stop 停止  zkServer.sh status 状态
        注意：在启动之前，关闭防火墙
        关闭firewall或者iptables：
        systemctl stop firewalld.service #停止firewall
        systemctl disable firewalld.service #禁止firewall开机启动
        firewall-cmd --state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）

    4、客户端打开操作：./zkCli.sh -server 192.168.66.128:2181,192.168.66.129:2181,192.168.66.130:2181

zookeeper使用场景(ZK会定期发布快照到硬盘存储，方便机器宕机丢失)
1、数据发布与订阅-简单、可靠、实时
    发布与订阅模型，即所谓的配置中心：发布者将数据发布到ZK节点，共订阅者或取数据，实现配置信息de集中式管理和动态更新。
    现实中实现的分布式方案有很多：
            1. 通过Redis或者Memcache来存储配置文件,通过集中式缓存系统来维护配置文件。
            2. 或者LowB点的就是通过数据库来维护,客户端通过内存来存放配置，每次配置更新时候，发出远程消息来通知各个客户端更新本地缓存。
            3. 通过Zookeeper的Wather事件机制，通知订阅的客户端。本次就是通过这种方式来实现。
2、命名服务：
   命名服务是指通过指定的名字来获取资源或者服务的地址，提供者的信息。利用Zookeeper很容易创建一个全局的路径，
   而这个路径就可以作为一个名字，它可以指向集群中的集群，提供的服务的地址，远程对象等。简单来说使用Zookeeper做命名服务就是用路径作为名字，
   路径上的数据就是其名字指向的实体。
3、分布式协调/通知：
     分布式协调/通知服务是分布式 系统中不可缺少的一个环节，是将不同的分布式组件有机的结合起来的关键所在，对于一个在多台机器上部署运行的应用而言，通常需要一个协调者（CoorDinator）来控制整个系统的运行流程，例如分布式事务的处理(Curator节点操作事务处理（CuratorTransactionResult）)、机器间互相协调等，同时，引入这样一个协调者，便于将分布式协调的职责从应用中分离出来，从而大大减少系统之间的耦合性，并且显著提高了系统的可扩展性。
   Zookeeper中持有Watcher注册与异步通知机制，能够很好的地实现分布式环境下不同机器，甚至是不同系统之间的协调与通知，从而实现对数据的变更的实时处理，基于Zookeeper实现分布式协调/通知的功能。
   通常的通知/协调机制通常方式。
           •系统调度模式：一个分布式系统与客户端系统两部分组成，控制台的职责就是需要发一些指令信息给所有的客户端，以控制他们相应的任务逻辑（机器间的限流控制、分布式的任务调度）操作人员发送通知实际是通过控制台改变某个节点的状态，然后Zookeeper将这些变化发送给注册了这个节点的Watcher的所有客户端。
          •工作进度汇报模式：在常见的任务分发系统中，通常任务被分发到不同的机器上执行后，需要实时的将自己的任务这行进度汇报给分发系统，这个时候可以通过Zookeeper来实现：
               1.通过临时节点是否存在，来确定任务机器的存活。
                2.各个任务机器实时的将自己的任务执行进度写在临时节点上去，一遍调度中心实时的获取任务执行进度，从而通过页面的直观显示给管理员查看任务的这行情况。
    总的来说，利用Zookeeper的watcher注册和异步通知功能，通知的发送者创建一个节点，并将通知的数据写入的该节点；通知的接受者则对该节点注册watch，当节点变化时，就算作通知的到来。
4、Zookeeper集群管理：
    随着分布式系统规模的扩大，集群中的机器规模也随之变大，因此，如何更好的进行集群系统管理显得越来越重要了。所谓的集群管理，包括集群监控和集群控制两大块，前者侧重与对集群运行状态的收集，后者是对集群进行操作与控制。
     场景：
         1)希望知道当前集群中究竟有多少的机器在工作。
         2)对集群中每台机器的运行状态进行数据收集
         3)对集群中机器进行上下线操作。
    在传统的基于Agent的分布式集群管理体系中，都是通过在集群中的每台机器上部署一个Agent，由这个Agent负责主动向指定的一个监控中心系统汇报自己所在机器的状态。在集群规模适中的场景下，这确实是一种在生产实践中广泛使用的解决方案，能够快速有效的实现分布式环境集群的监控，但是一旦系统业务场景增多，集群规模变大之后，该解决方案的弊端就会显现出来：
           1)大规模的升级困难，以客户端形式存在的Agent，每一个客户端都需要升级部署。
          2)统一的Agent无法满足多要的需求，对于不同场景的业务可能监控的需求都会不一样，所以不适合一个统一的Agent来提供。
           3)编程语言多样性，各种系统层出不穷，如果使用传统的Agent，那么需要提供各种需要的Agent客户端，另一方面似的“监控中心”对异构系统的数据进行整合上面临巨大的挑战。

     Zookeeper具有一下两大特性。
           1)客户端如果对Zookeeper的一个数据节点注册Wather监听，那么当数据节点的内容或者是其子节点列表发生变更时，Zookeeper服务器就会向订阅的客户端发送变更通知。
          2)对Zookeeper创建的临时节点，一旦客户端与服务端之间会话失效，那么该临时节点也就被自动清除。
     如：监控系统在/clusterServer节点上注册一个Watcher监听，那么但凡进行动态添加机器操作，就会在/clusterServer节点下创建一个临时节点：/clusterServer/[HostName].这样一来。监控系统就能实时的检测到机器的变动情况，至于后续的处理就是监控系统的业务了。
5、Master选举：
    在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。
   利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。
   另外，这种场景演化一下，就是动态Master选举。这就要用到EPHEMERAL_SEQUENTIAL类型节点的特性了。
   上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终在ZK上创建结果的一种可能情况是这样：
    /currentMaster/{sessionId}-1 ,
    /currentMaster/{sessionId}-2,
    /currentMaster/{sessionId}-3 …..
     每次选取序列号最小的那个机器作为Master，
     如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。
          1. 在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行全量索引的生成，然后同步到集群中其它机器。另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向一个地方获取master。
         2. 在Hbase中，也是使用ZooKeeper来实现动态HMaster的选举。在Hbase实现中，会在ZK上存储一些ROOT表的地址和HMaster的地址，HRegionServer也会把自己以临时节点（Ephemeral）的方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的存活状态，同时，一旦HMaster出现问题，会重新选举出一个HMaster来运行，从而避免了HMaster的单点问题
6、分布式锁
  分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个排他锁、一个是共享锁的概念；
     1.排他锁：
      保证当前有且只有一个事务获得锁，并且锁被释放后，所有正在等待获取锁的事务都能够被通知到；
   通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建/distribute_lock节点下创建临时子节点/distribute_lock/lock，同时没有创建成功的客户端就可以在/distribute_lock节点注册一个子节点变更的Watcher监听,，最终成功创建的那个客户端也即拥有了这把锁。
    分布式锁(InterProcessMutex)
       InterProcessMutex 类详解步骤：获取锁的过程步骤：

       1.acquire方法，根据当前线程获取锁对象，判断当前的线程是否已经获取锁，此处则代表可重入；
       2.获取锁方法，String lockPath = internals.attemptLock(time, unit, getLockNodeBytes());

       3.当获取到锁时，则把锁数据放入内存对象

     共享锁：
         共享锁又称读锁，同样是一种基本的锁类型。如果事务T1对数据对象O1加上了共享锁，那么当前事务只能对O1进行读取操作，其他事务只能等待这个数据对象加共享锁，一直到该数据对象上的所有共享锁都被释放。
      实现的思路：
        1)每启动一个进程, 则在zookeeper中创建一个带序列的临时节点
        2)客户端调用getChildren()接口来获取所有已经创建的子节点。
        3)如果无法获取共享锁，那么就调用exist()来对比比自己小的节点，注册Wather。具体：
           读请求：向比自己序号小的最后一个写请求节点注册Wather监听。
           写请求：向比自己序号小娥最后一个节点注册Wather。
        4)等待Wather通知，继续进入步骤2：
7、分布式队列
      队列有很多种产品，大都是消息系统所实现的，像ActiveMQ,JBossMQ,RabbitMQ,IBM-MQ等。分步式队列产品并不太多，像Beanstalkd。
   我们主要介绍基于Zookeeper实现的分布式队列。分布式队列，简单地分为两大类，一种是常规的FIFO队列，另外一种则是要等到队列元素聚集之后才统一执行的Barrier模式：
   FIFO：先进先出
   先进先出(FIFO)队列，是消息队列最基本的一种实现形式，先发出的先消费。
   实现的思路也非常简单，在/queue-fifo的目录下创建 SEQUENTIAL 类型的子目录 /x(i)，这样就能保证所有成员加入队列时都是有编号的，出队列时通过 getChildren( ) 方法可以返回当前所有的队列中的元素，然后消费其中最小的一个，这样就能保证FIFO。
8、Barrier：分布式屏障：
     Barrier原意是指障碍物、屏障，而在分布式系统中，特指系统之间的一个协助条件，规定了一个队列的元素必须都聚集后才能统一进行安排，否则一直等待，在一些分布式并行计算的应用场景上：最终合并计算需要基于很多的并行计算的子结果来进行。在JDK中自带了CyclicBarrier实现。
   在分布式环境中通过Curator中提供的DistributedBarrier来实现分布式Barrier的：
   实现的思路：
     1、通过默认节点/queue_barrier初始化一个数字N 代表循环值。同时注册对子节点列表变更的Wather监听事件。
     2、通过getData()接口获取/queue_barrier几点的数据内容：5；
      通过调用getChildren()接口获取/queue_barrier节点下的所有子节点，即获取队列的所有元素，
     3、统计子节点的个数。
     4、如果子节点的个数不足10个，那么需要等待。
     5、接受到Wather通知后重复步骤2。

